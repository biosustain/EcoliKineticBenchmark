{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[0].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[0].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[0]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(null);\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.11.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.11.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.11.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.11.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.11.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.11.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.11.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.11.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.11.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.11.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.11.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.11.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.11.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.11.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.11.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.11.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.11.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.11.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.11.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.11.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cobra\n",
    "from cameo import pfba\n",
    "from cameo.flux_analysis.simulation import room, lmoma\n",
    "\n",
    "import escher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_escher(result):\n",
    "    escher.Builder(\n",
    "    map_name=\"e_coli_core.Core metabolism\",\n",
    "    reaction_data=result.fluxes.to_dict(),\n",
    ").display_in_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataframe(\n",
    "    solution, sample=\"WT\", author=\"iML1515\", glucose_flux_id=\"EX_glc__D_e\"\n",
    "):\n",
    "    # Prepare basic DataFrame\n",
    "    df = pd.DataFrame(solution.fluxes)\n",
    "    df.index = df.index.rename(\"ID\")\n",
    "    df = df.reset_index()\n",
    "    df = df.assign(sample_id=sample)\n",
    "\n",
    "    # rename some columns to be more compatible with other simulations\n",
    "    df = df.assign(author=author)\n",
    "    df = df.assign(BiGG_ID=df.ID)\n",
    "    df = df.rename({\"fluxes\": \"flux\"}, axis=1)\n",
    "\n",
    "    # calculate normalized fluxes\n",
    "    glucose_uptake = -1 * df[df[\"ID\"] == glucose_flux_id][\"flux\"].values[0]\n",
    "    df = df.assign(normalized_flux=lambda x: x.flux * 100 / glucose_uptake)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define IDs of knocked-out reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "knockouts = [\n",
    "    {\"gene\": \"fbaA\", \"id\": \"FBA\"},\n",
    "    {\"gene\": \"fbaB\", \"id\": \"FBA\"},\n",
    "    {\"gene\": \"fbp\", \"id\": \"FBP\"},\n",
    "    {\"gene\": \"gnd\", \"id\": \"GND\"},\n",
    "    {\"gene\": \"pfkA\", \"id\": \"PFK\"},\n",
    "    {\"gene\": \"pfkB\", \"id\": \"PFK\"},\n",
    "    {\"gene\": \"pgi\", \"id\": \"PGI\"},\n",
    "    {\"gene\": \"pgl\", \"id\": \"PGL\"},\n",
    "    {\"gene\": \"ppsA\", \"id\": \"PPS\"},\n",
    "    {\"gene\": \"pts\", \"id\": \"GLCptspp\"},\n",
    "    {\"gene\": \"pykA\", \"id\": \"PYK\"},\n",
    "    {\"gene\": \"pykF\", \"id\": \"PYK\"},\n",
    "    {\"gene\": \"rpe\", \"id\": \"RPE\"},\n",
    "    {\"gene\": \"rpiA\", \"id\": \"RPI\"},\n",
    "    {\"gene\": \"rpiB\", \"id\": \"RPI\"},\n",
    "    {\"gene\": \"sdhCD\", \"id\": \"SUCDi\"},\n",
    "    {\"gene\": \"sucAB\", \"id\": \"AKGDH\"},\n",
    "    {\"gene\": \"talA\", \"id\": \"TALA\"},\n",
    "    {\"gene\": \"tktA\", \"id\": \"TKT1\"},\n",
    "    {\"gene\": \"tktB\", \"id\": \"TKT1\"},\n",
    "    {\"gene\": \"tpi\", \"id\": \"TPI\"},\n",
    "    {\"gene\": \"zwf\", \"id\": \"G6PDH2r\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dilution simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iML1515 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cobra.io.load_json_model('../../../DataAnalysis/DataIntegrationProject/models/iML1515.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize glucose consumption from medium - equiv to max exchange. \n",
    "model.objective = \"EX_glc__D_e\"\n",
    "model.objective_direction = \"max\"\n",
    "# make glucose uptake to be through Pts\n",
    "model.reactions.GLCptspp.bounds = (0.0,1000)\n",
    "\n",
    "# Simulate D 0.2 h-1\n",
    "model.reactions.BIOMASS_Ec_iML1515_core_75p37M.bounds = (0.19,0.21)\n",
    "# Glucose uptake rate should more or less match Ishii, 2007\n",
    "# GUR for WT @ aerobic glucose = 2.87 mmol/h/gDW\n",
    "model.reactions.GLCptspp.bounds = (2.86,2.88)\n",
    "\n",
    "dilution_result = pfba(model)\n",
    "all_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write WT information\n",
    "df = prepare_dataframe(dilution_result, author=\"iML1515\", sample=\"WT\", glucose_flux_id=\"EX_glc__D_e\")\n",
    "\n",
    "df.to_csv('../data/simulation_results/COBRA/WT_02.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([all_data, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for reaction in knockouts:\n",
    "    with model:\n",
    "        ko_gene = reaction[\"gene\"]\n",
    "        # Simulate knockout\n",
    "        model.reactions.get_by_id(reaction[\"id\"]).knock_out()\n",
    "        lmoma_result = lmoma(model, reference=dilution_result.fluxes)\n",
    "        df = prepare_dataframe(lmoma_result, author=\"iML1515\", sample=ko_gene, glucose_flux_id=\"EX_glc__D_e\")\n",
    "        df.to_csv(f\"../data/simulation_results/COBRA/delta_{ko_gene}.csv\")\n",
    "\n",
    "        all_data = pd.concat([all_data, df], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv(\"../data/simulation_results/COBRA/iML1515/knockouts_all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make calculations for the e_coli_core model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cobra.io.load_json_model('../../../DataAnalysis/DataIntegrationProject/models/e_coli_core.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.objective = \"EX_glc__D_e\"\n",
    "model.objective_direction = \"max\"\n",
    "\n",
    "# Simulate D 0.2 h-1\n",
    "model.reactions.BIOMASS_Ecoli_core_w_GAM.bounds = (0.19,0.21)\n",
    "# Glucose uptake rate should more or less match Ishii, 2007\n",
    "# GUR for WT @ aerobic glucose = 2.87 mmol/h/gDW\n",
    "model.reactions.GLCpts.bounds = (2.86,2.88)\n",
    "\n",
    "dilution_result = pfba(model)\n",
    "all_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write WT information\n",
    "df = prepare_dataframe(dilution_result, author=\"Ec_core\", sample=\"WT\", glucose_flux_id=\"EX_glc__D_e\")\n",
    "\n",
    "df.to_csv('../data/simulation_results/COBRA/core_model/WT_02.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([all_data, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worinkg on gene fbaA\n",
      "Worinkg on gene fbaB\n",
      "Worinkg on gene fbp\n",
      "Worinkg on gene gnd\n",
      "Worinkg on gene pfkA\n",
      "Worinkg on gene pfkB\n",
      "Worinkg on gene pgi\n",
      "Worinkg on gene pgl\n",
      "Worinkg on gene ppsA\n",
      "Worinkg on gene pts\n",
      "Unable to grow pts! Filling flux data with zeros\n",
      "Worinkg on gene pykA\n",
      "Worinkg on gene pykF\n",
      "Worinkg on gene rpe\n",
      "Worinkg on gene rpiA\n",
      "Unable to grow rpiA! Filling flux data with zeros\n",
      "Worinkg on gene rpiB\n",
      "Unable to grow rpiB! Filling flux data with zeros\n",
      "Worinkg on gene sdhCD\n",
      "Worinkg on gene sucAB\n",
      "Worinkg on gene talA\n",
      "Worinkg on gene tktA\n",
      "Worinkg on gene tktB\n",
      "Worinkg on gene tpi\n",
      "Worinkg on gene zwf\n"
     ]
    }
   ],
   "source": [
    "for reaction in knockouts:\n",
    "    with model:        \n",
    "        ko_gene = reaction[\"gene\"]\n",
    "        print(f\"Worinkg on gene {ko_gene}\")\n",
    "        try:\n",
    "            # Simulate knockout, it may not grow at all\n",
    "            model.reactions.get_by_id(reaction[\"id\"]).knock_out()\n",
    "            lmoma_result = lmoma(model, reference=dilution_result.fluxes)\n",
    "            df = prepare_dataframe(lmoma_result, author=\"Ec_core\", sample=ko_gene, glucose_flux_id=\"EX_glc__D_e\")\n",
    "        except:\n",
    "            print(f\"Unable to grow {ko_gene}! Filling flux data with zeros\")\n",
    "            df = prepare_dataframe(dilution_result, sample=ko_gene, author=\"Ec_core\", glucose_flux_id=\"EX_glc__D_e\" )\n",
    "            df.flux = 0\n",
    "        \n",
    "        df.to_csv(f\"../data/simulation_results/COBRA/core_model/delta_{ko_gene}.csv\")\n",
    "\n",
    "        all_data = pd.concat([all_data, df], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv(\"../data/simulation_results/COBRA/core_model/knockouts_all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make calculations for the EColiCore2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding exchange reaction EX_Biomass for boundary metabolite: Biomass\n",
      "Adding exchange reaction EX_4CRSOL_ex for boundary metabolite: 4CRSOL_ex\n",
      "Adding exchange reaction EX_5DRIB_ex for boundary metabolite: 5DRIB_ex\n",
      "Adding exchange reaction EX_ac_ex for boundary metabolite: ac_ex\n",
      "Adding exchange reaction EX_adp_c for boundary metabolite: adp_c\n",
      "Adding exchange reaction EX_AMOB_ex for boundary metabolite: AMOB_ex\n",
      "Adding exchange reaction EX_ca2_ex for boundary metabolite: ca2_ex\n",
      "Adding exchange reaction EX_cl_ex for boundary metabolite: cl_ex\n",
      "Adding exchange reaction EX_co2_ex for boundary metabolite: co2_ex\n",
      "Adding exchange reaction EX_coa_c for boundary metabolite: coa_c\n",
      "Adding exchange reaction EX_cobalt2_ex for boundary metabolite: cobalt2_ex\n",
      "Adding exchange reaction EX_cu2_ex for boundary metabolite: cu2_ex\n",
      "Adding exchange reaction EX_etoh_ex for boundary metabolite: etoh_ex\n",
      "Adding exchange reaction EX_fe2_ex for boundary metabolite: fe2_ex\n",
      "Adding exchange reaction EX_fe3_ex for boundary metabolite: fe3_ex\n",
      "Adding exchange reaction EX_foex for boundary metabolite: foex\n",
      "Adding exchange reaction EX_glc__D_ex for boundary metabolite: glc__D_ex\n",
      "Adding exchange reaction EX_glyc_ex for boundary metabolite: glyc_ex\n",
      "Adding exchange reaction EX_h_ex for boundary metabolite: h_ex\n",
      "Adding exchange reaction EX_h2_ex for boundary metabolite: h2_ex\n",
      "Adding exchange reaction EX_h2o_ex for boundary metabolite: h2o_ex\n",
      "Adding exchange reaction EX_k_ex for boundary metabolite: k_ex\n",
      "Adding exchange reaction EX_lac_ex for boundary metabolite: lac_ex\n",
      "Adding exchange reaction EX_meoh_ex for boundary metabolite: meoh_ex\n",
      "Adding exchange reaction EX_mg2_ex for boundary metabolite: mg2_ex\n",
      "Adding exchange reaction EX_mn2_ex for boundary metabolite: mn2_ex\n",
      "Adding exchange reaction EX_mobd_ex for boundary metabolite: mobd_ex\n",
      "Adding exchange reaction EX_mqn8_c for boundary metabolite: mqn8_c\n",
      "Adding exchange reaction EX_MTHTHF_ex for boundary metabolite: MTHTHF_ex\n",
      "Adding exchange reaction EX_nad_c for boundary metabolite: nad_c\n",
      "Adding exchange reaction EX_nadp_c for boundary metabolite: nadp_c\n",
      "Adding exchange reaction EX_nh4_ex for boundary metabolite: nh4_ex\n",
      "Adding exchange reaction EX_ni2_ex for boundary metabolite: ni2_ex\n",
      "Adding exchange reaction EX_o2_ex for boundary metabolite: o2_ex\n",
      "Adding exchange reaction EX_pi_c for boundary metabolite: pi_c\n",
      "Adding exchange reaction EX_pi_ex for boundary metabolite: pi_ex\n",
      "Adding exchange reaction EX_q8_c for boundary metabolite: q8_c\n",
      "Adding exchange reaction EX_so4_ex for boundary metabolite: so4_ex\n",
      "Adding exchange reaction EX_succ_ex for boundary metabolite: succ_ex\n",
      "Adding exchange reaction EX_zn2_ex for boundary metabolite: zn2_ex\n"
     ]
    }
   ],
   "source": [
    "model = cobra.io.read_sbml_model('../../../DataAnalysis/DataIntegrationProject/models/EColiCore2_compressed_bigg_names.sbml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize glucose consumption from medium - equiv to max exchange. \n",
    "model.objective = \"EX_glc__D_ex\"\n",
    "model.objective_direction = \"max\"\n",
    "\n",
    "# Simulate D 0.2 h-1\n",
    "model.reactions.Growth.bounds = (0.19,0.21)\n",
    "# Glucose uptake rate should more or less match Ishii, 2007\n",
    "# GUR for WT @ aerobic glucose = 2.87 mmol/h/gDW\n",
    "model.reactions.GLCptspp.bounds = (2.86,2.88)\n",
    "\n",
    "dilution_result = pfba(model)\n",
    "all_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_escher(dilution_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_dataframe(dilution_result, author=\"ECC2\", glucose_flux_id=\"EX_glc__D_ex\")\n",
    "df.to_csv('../data/simulation_results/COBRA/ECC2/WT_02.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([all_data, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on gene fbaA\n",
      "Working on gene fbaB\n",
      "Working on gene fbp\n",
      "Working on gene gnd\n",
      "Working on gene pfkA\n",
      "Working on gene pfkB\n",
      "Working on gene pgi\n",
      "Working on gene pgl\n",
      "Working on gene ppsA\n",
      "Working on gene pts\n",
      "Working on gene pykA\n",
      "Working on gene pykF\n",
      "Working on gene rpe\n",
      "Working on gene rpiA\n",
      "Unable to grow rpiA! Filling flux data with zeros\n",
      "Working on gene rpiB\n",
      "Unable to grow rpiB! Filling flux data with zeros\n",
      "Working on gene sdhCD\n",
      "Working on gene sucAB\n",
      "Working on gene talA\n",
      "Working on gene tktA\n",
      "Working on gene tktB\n",
      "Working on gene tpi\n",
      "Working on gene zwf\n"
     ]
    }
   ],
   "source": [
    "for reaction in knockouts:\n",
    "    with model:        \n",
    "        ko_gene = reaction[\"gene\"]\n",
    "        print(f\"Working on gene {ko_gene}\")\n",
    "        try:\n",
    "            # Simulate knockout, it may not grow at all\n",
    "            model.reactions.get_by_id(reaction[\"id\"]).knock_out()\n",
    "            lmoma_result = lmoma(model, reference=dilution_result.fluxes)\n",
    "            df = prepare_dataframe(lmoma_result, author=\"ECC2\", sample=ko_gene, glucose_flux_id=\"EX_glc__D_ex\")\n",
    "        except:\n",
    "            print(f\"Unable to grow {ko_gene}! Filling flux data with zeros\")\n",
    "            df = prepare_dataframe(dilution_result, sample=ko_gene, author=\"ECC2\", glucose_flux_id=\"EX_glc__D_ex\" )\n",
    "            df.flux = 0\n",
    "        \n",
    "        df.to_csv(f\"../data/simulation_results/COBRA/ECC2/delta_{ko_gene}.csv\")\n",
    "\n",
    "        all_data = pd.concat([all_data, df], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv(\"../data/simulation_results/COBRA/ECC2/knockouts_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constrain WT model by experimentally measured fluxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ishii_df = pd.read_csv(\"../data/datasets/ishii2007_tidy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ishii_df\n",
    "# this regexp matches deletions starting with d like dpgi\n",
    "df[\"sample_id\"] = df.Genotype.str.extract(r\"d(\\w+)\")\n",
    "df.loc[df.Genotype == \"WT\", \"sample_id\"] = \"WT\"\n",
    "\n",
    "df = df.assign(author=\"Ishii\")\n",
    "df = df.rename(\n",
    "    {\n",
    "        \"Measurement_ID\": \"BiGG_ID\",\n",
    "        \"Original_Value\": \"normalized_flux\",\n",
    "        \"Value\": \"flux\",\n",
    "        \"Original_ID\": \"ID\",\n",
    "    },\n",
    "    axis=1,\n",
    ")\n",
    "df = df[df['Measurement_Type'] == 'flux']\n",
    "df.loc[df[\"BiGG_ID\"] == \"PYKF\", \"BiGG_ID\"] = \"PYK\"\n",
    "\n",
    "df = df[[\"flux\", \"ID\", \"BiGG_ID\", \"author\", \"sample_id\", \"normalized_flux\"]]\n",
    "exp_results = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_data = exp_results.query(\"sample_id == 'WT'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flux</th>\n",
       "      <th>ID</th>\n",
       "      <th>BiGG_ID</th>\n",
       "      <th>author</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>normalized_flux</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>ACALD</td>\n",
       "      <td>ACALD</td>\n",
       "      <td>Ishii</td>\n",
       "      <td>WT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>2.4167</td>\n",
       "      <td>ACONTa</td>\n",
       "      <td>ACONTa</td>\n",
       "      <td>Ishii</td>\n",
       "      <td>WT</td>\n",
       "      <td>84.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>1.6874</td>\n",
       "      <td>AKGDH</td>\n",
       "      <td>AKGDH</td>\n",
       "      <td>Ishii</td>\n",
       "      <td>WT</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>2.4167</td>\n",
       "      <td>CS</td>\n",
       "      <td>CS</td>\n",
       "      <td>Ishii</td>\n",
       "      <td>WT</td>\n",
       "      <td>84.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.2431</td>\n",
       "      <td>EX_akg(e)</td>\n",
       "      <td>EX_akg(e)</td>\n",
       "      <td>Ishii</td>\n",
       "      <td>WT</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       flux         ID    BiGG_ID author sample_id  normalized_flux\n",
       "991  0.0000      ACALD      ACALD  Ishii        WT              0.0\n",
       "992  2.4167     ACONTa     ACONTa  Ishii        WT             84.5\n",
       "993  1.6874      AKGDH      AKGDH  Ishii        WT             59.0\n",
       "994  2.4167         CS         CS  Ishii        WT             84.5\n",
       "995  0.2431  EX_akg(e)  EX_akg(e)  Ishii        WT              8.5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify which fluxes could be constrainted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_fluxes = set(dilution_result.fluxes.index).intersection(set(exp_data.BiGG_ID.unique()))\n",
    "common_fluxes.remove(\"RPI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACALD',\n",
       " 'ACONTa',\n",
       " 'AKGDH',\n",
       " 'CS',\n",
       " 'EDA',\n",
       " 'FBA',\n",
       " 'FUM',\n",
       " 'G6PDH2r',\n",
       " 'GAPD',\n",
       " 'GLCptspp',\n",
       " 'GND',\n",
       " 'ICDHyr',\n",
       " 'ICL',\n",
       " 'LDH_D',\n",
       " 'MALS',\n",
       " 'MDH',\n",
       " 'ME1',\n",
       " 'PDH',\n",
       " 'PGI',\n",
       " 'PGM',\n",
       " 'PPC',\n",
       " 'PTAr',\n",
       " 'PYK',\n",
       " 'RPE',\n",
       " 'SUCDi',\n",
       " 'TALA',\n",
       " 'TKT1',\n",
       " 'TKT2',\n",
       " 'TPI'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting bounds for reaction ACALD\n",
      "Setting bounds for reaction ACONTa\n",
      "Setting bounds for reaction AKGDH\n",
      "Setting bounds for reaction CS\n",
      "Setting bounds for reaction FBA\n",
      "Setting bounds for reaction FUM\n",
      "Setting bounds for reaction G6PDH2r\n",
      "Setting bounds for reaction GAPD\n",
      "Setting bounds for reaction GLCptspp\n",
      "Setting bounds for reaction GND\n",
      "Setting bounds for reaction ICDHyr\n",
      "Setting bounds for reaction ICL\n",
      "Setting bounds for reaction LDH_D\n",
      "Setting bounds for reaction MALS\n",
      "Setting bounds for reaction MDH\n",
      "Setting bounds for reaction ME1\n",
      "Setting bounds for reaction PDH\n",
      "Setting bounds for reaction PGI\n",
      "Setting bounds for reaction PGM\n",
      "Setting bounds for reaction PPC\n",
      "Setting bounds for reaction PTAr\n",
      "Setting bounds for reaction PYK\n",
      "Setting bounds for reaction RPE\n",
      "Setting bounds for reaction SUCDi\n",
      "Setting bounds for reaction TALA\n",
      "Setting bounds for reaction TKT1\n",
      "Setting bounds for reaction TKT2\n",
      "Setting bounds for reaction TPI\n",
      "Setting bounds for reaction EDA\n"
     ]
    }
   ],
   "source": [
    "df = exp_data.query(\"BiGG_ID in @common_fluxes\")\n",
    "exp_model = model.copy()\n",
    "\n",
    "for row in df.itertuples():\n",
    "        print(f\"Setting bounds for reaction {row.BiGG_ID}\")\n",
    "        r = exp_model.reactions.get_by_id(row.BiGG_ID)\n",
    "        r.bounds = (row.flux - 0.1, row.flux + 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on gene fbaA\n",
      "Working on gene fbaB\n",
      "Working on gene fbp\n",
      "Working on gene gnd\n",
      "Working on gene pfkA\n",
      "Working on gene pfkB\n",
      "Working on gene pgi\n",
      "Working on gene pgl\n",
      "Unable to grow pgl! Filling flux data with zeros\n",
      "Working on gene ppsA\n",
      "Unable to grow ppsA! Filling flux data with zeros\n",
      "Working on gene pts\n",
      "Working on gene pykA\n",
      "Working on gene pykF\n",
      "Working on gene rpe\n",
      "Unable to grow rpe! Filling flux data with zeros\n",
      "Working on gene rpiA\n",
      "Unable to grow rpiA! Filling flux data with zeros\n",
      "Working on gene rpiB\n",
      "Unable to grow rpiB! Filling flux data with zeros\n",
      "Working on gene sdhCD\n",
      "Unable to grow sdhCD! Filling flux data with zeros\n",
      "Working on gene sucAB\n",
      "Unable to grow sucAB! Filling flux data with zeros\n",
      "Working on gene talA\n",
      "Unable to grow talA! Filling flux data with zeros\n",
      "Working on gene tktA\n",
      "Unable to grow tktA! Filling flux data with zeros\n",
      "Working on gene tktB\n",
      "Unable to grow tktB! Filling flux data with zeros\n",
      "Working on gene tpi\n",
      "Unable to grow tpi! Filling flux data with zeros\n",
      "Working on gene zwf\n",
      "Unable to grow zwf! Filling flux data with zeros\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.DataFrame()\n",
    "# Calculate WT\n",
    "exp_dilution_result = pfba(exp_model)\n",
    "df = prepare_dataframe(exp_dilution_result, sample=\"WT\", author=\"Exp_ECC2\", glucose_flux_id=\"EX_glc__D_ex\" )\n",
    "df.to_csv(\"../data/simulation_results/COBRA/Exp_ECC2/WT_02.csv\")\n",
    "\n",
    "with model:\n",
    "    for reaction in knockouts: \n",
    "        ko_gene = reaction[\"gene\"]\n",
    "        print(f\"Working on gene {ko_gene}\")\n",
    "        try:\n",
    "            # Simulate knockout, it may not grow at all\n",
    "            model.reactions.get_by_id(reaction[\"id\"]).knock_out()\n",
    "            lmoma_result = lmoma(model, reference=exp_dilution_result.fluxes)\n",
    "            df = prepare_dataframe(lmoma_result, sample=ko_gene, author=\"Exp_ECC2\", glucose_flux_id=\"EX_glc__D_ex\" )\n",
    "        except:\n",
    "            print(f\"Unable to grow {ko_gene}! Filling flux data with zeros\")\n",
    "            df = prepare_dataframe(exp_dilution_result, sample=ko_gene, author=\"Exp_ECC2\", glucose_flux_id=\"EX_glc__D_ex\" )\n",
    "            df.flux = 0\n",
    "        df.to_csv(f\"../data/simulation_results/COBRA/Exp_ECC2/delta_{ko_gene}.csv\")\n",
    "    \n",
    "        all_data = pd.concat([all_data, df], sort=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cameo-conda",
   "language": "python",
   "name": "cameo-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
