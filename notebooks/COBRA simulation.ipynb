{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[0].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[0].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[0]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(null);\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.11.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.11.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.11.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.11.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.11.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.11.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.11.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.11.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.11.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.11.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.11.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.11.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.11.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.11.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.11.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.11.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.11.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.11.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.11.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.11.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cobra\n",
    "from cameo import pfba\n",
    "from cameo.flux_analysis.simulation import room, lmoma\n",
    "\n",
    "import escher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define IDs of knocked-out reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "knockouts = [\n",
    "    {\"gene\": \"fbaA\", \"id\": \"FBA\"},\n",
    "    {\"gene\": \"fbaB\", \"id\": \"FBA\"},\n",
    "    {\"gene\": \"fbp\", \"id\": \"FBP\"},\n",
    "    {\"gene\": \"gnd\", \"id\": \"GND\"},\n",
    "    {\"gene\": \"pfkA\", \"id\": \"PFK\"},\n",
    "    {\"gene\": \"pfkB\", \"id\": \"PFK\"},\n",
    "    {\"gene\": \"pgi\", \"id\": \"PGI\"},\n",
    "    {\"gene\": \"pgl\", \"id\": \"PGL\"},\n",
    "    {\"gene\": \"ppsA\", \"id\": \"PPS\"},\n",
    "    {\"gene\": \"pts\", \"id\": \"GLCptspp\"},\n",
    "    {\"gene\": \"pykA\", \"id\": \"PYK\"},\n",
    "    {\"gene\": \"pykF\", \"id\": \"PYK\"},\n",
    "    {\"gene\": \"rpe\", \"id\": \"RPE\"},\n",
    "    {\"gene\": \"rpiA\", \"id\": \"RPI\"},\n",
    "    {\"gene\": \"rpiB\", \"id\": \"RPI\"},\n",
    "    {\"gene\": \"sdhCD\", \"id\": \"SUCDi\"},\n",
    "    {\"gene\": \"sucAB\", \"id\": \"AKGDH\"},\n",
    "    {\"gene\": \"talA\", \"id\": \"TALA\"},\n",
    "    {\"gene\": \"tktA\", \"id\": \"TKT1\"},\n",
    "    {\"gene\": \"tktB\", \"id\": \"TKT1\"},\n",
    "    {\"gene\": \"tpi\", \"id\": \"TPI\"},\n",
    "    {\"gene\": \"zwf\", \"id\": \"G6PDH2r\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dilution simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iML1515 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cobra.io.load_json_model('../../../DataAnalysis/DataIntegrationProject/models/iML1515.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize glucose consumption from medium - equiv to max exchange. \n",
    "model.objective = \"EX_glc__D_e\"\n",
    "model.objective_direction = \"max\"\n",
    "# make glucose uptake to be through Pts\n",
    "model.reactions.GLCptspp.bounds = (0.0,1000)\n",
    "\n",
    "# Simulate D 0.2 h-1\n",
    "model.reactions.BIOMASS_Ec_iML1515_core_75p37M.bounds = (0.19,0.21)\n",
    "# Glucose uptake rate should more or less match Ishii, 2007\n",
    "# GUR for WT @ aerobic glucose = 2.87 mmol/h/gDW\n",
    "model.reactions.GLCptspp.bounds = (2.86,2.88)\n",
    "\n",
    "dilution_result = pfba(model)\n",
    "all_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write WT information\n",
    "df = pd.DataFrame(dilution_result.fluxes)\n",
    "df.index = df.index.rename(\"ID\")\n",
    "df = df.reset_index()\n",
    "df = df.assign(sample_id=\"WT\")\n",
    "        \n",
    "# rename some columns to be more compatible with other simulations\n",
    "df = df.assign(author = \"iML1515\")\n",
    "df = df.assign(BiGG_ID = df.ID)\n",
    "df = df.rename({\"fluxes\" : \"flux\"}, axis = 1)\n",
    "        \n",
    "# calculate normalized fluxes \n",
    "glucose_uptake = -1 * df[df['ID'] == 'EX_glc__D_e']['flux'].values[0]\n",
    "df = df.assign(normalized_flux = lambda x: x.flux * 100 / glucose_uptake)\n",
    "\n",
    "df.to_csv('../data/simulation_results/COBRA/iML1515/WT_02.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([all_data, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for reaction in knockouts:\n",
    "    with model:\n",
    "        ko_gene = reaction[\"gene\"]\n",
    "        # Simulate knockout\n",
    "        model.reactions.get_by_id(reaction[\"id\"]).knock_out()\n",
    "        lmoma_result = lmoma(model, reference=dilution_result.fluxes)\n",
    "\n",
    "        df = pd.DataFrame(lmoma_result.fluxes)\n",
    "        df.index = df.index.rename(\"ID\")\n",
    "        df = df.reset_index()\n",
    "        df = df.assign(sample_id=reaction[\"gene\"])\n",
    "        \n",
    "        # rename some columns to be more compatible with other simulations\n",
    "        df = df.assign(author = \"iML1515\")\n",
    "        df = df.assign(BiGG_ID = df.ID)\n",
    "        df = df.rename({\"fluxes\" : \"flux\"}, axis = 1)\n",
    "        \n",
    "        # calculate normalized fluxes \n",
    "        glucose_uptake = -1 * df[df['ID'] == 'EX_glc__D_e']['flux'].values[0]\n",
    "        df = df.assign(normalized_flux = lambda x: x.flux * 100 / glucose_uptake)\n",
    "        \n",
    "        df.to_csv(f\"../data/simulation_results/COBRA/delta_{ko_gene}.csv\")\n",
    "\n",
    "        all_data = pd.concat([all_data, df], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv(\"../data/simulation_results/COBRA/iML1515/knockouts_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: You must interrupt the kernel to end this command\n",
      "\n",
      "Serving to http://127.0.0.1:7655/\n",
      "[Ctrl-C to exit from terminal, or Ctrl-M i i to interrupt notebook kernel]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/Feb/2019 15:33:14] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# escher.Builder(\n",
    "#     map_name=\"e_coli_core.Core metabolism\",\n",
    "#     model=model,\n",
    "#     reaction_data=dilution_result.fluxes.to_dict(),\n",
    "# ).display_in_browser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make calculations for the e_coli_core model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cobra.io.load_json_model('../../../DataAnalysis/DataIntegrationProject/models/e_coli_core.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.objective = \"EX_glc__D_e\"\n",
    "model.objective_direction = \"max\"\n",
    "\n",
    "# Simulate D 0.2 h-1\n",
    "model.reactions.BIOMASS_Ecoli_core_w_GAM.bounds = (0.19,0.21)\n",
    "# Glucose uptake rate should more or less match Ishii, 2007\n",
    "# GUR for WT @ aerobic glucose = 2.87 mmol/h/gDW\n",
    "model.reactions.GLCpts.bounds = (2.86,2.88)\n",
    "\n",
    "dilution_result = pfba(model)\n",
    "all_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write WT information\n",
    "df = pd.DataFrame(dilution_result.fluxes)\n",
    "df.index = df.index.rename(\"ID\")\n",
    "df = df.reset_index()\n",
    "df = df.assign(sample_id=\"WT\")\n",
    "        \n",
    "# rename some columns to be more compatible with other simulations\n",
    "df = df.assign(author = \"Ec_core\")\n",
    "df = df.assign(BiGG_ID = df.ID)\n",
    "df = df.rename({\"fluxes\" : \"flux\"}, axis = 1)\n",
    "        \n",
    "# calculate normalized fluxes \n",
    "glucose_uptake = -1 * df[df['ID'] == 'EX_glc__D_e']['flux'].values[0]\n",
    "df = df.assign(normalized_flux = lambda x: x.flux * 100 / glucose_uptake)\n",
    "\n",
    "df.to_csv('../data/simulation_results/COBRA/core_model/WT_02.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([all_data, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worinkg on gene fbaA\n",
      "Worinkg on gene fbaB\n",
      "Worinkg on gene fbp\n",
      "Worinkg on gene gnd\n",
      "Worinkg on gene pfkA\n",
      "Worinkg on gene pfkB\n",
      "Worinkg on gene pgi\n",
      "Worinkg on gene pgl\n",
      "Worinkg on gene ppsA\n",
      "Worinkg on gene pts\n",
      "Worinkg on gene pykA\n",
      "Worinkg on gene pykF\n",
      "Worinkg on gene rpe\n",
      "Worinkg on gene rpiA\n",
      "Worinkg on gene rpiB\n",
      "Worinkg on gene sdhCD\n",
      "Worinkg on gene sucAB\n",
      "Worinkg on gene talA\n",
      "Worinkg on gene tktAB\n",
      "Worinkg on gene tktB\n",
      "Worinkg on gene tpi\n",
      "Worinkg on gene zwf\n"
     ]
    }
   ],
   "source": [
    "for reaction in knockouts:\n",
    "    with model:        \n",
    "        ko_gene = reaction[\"gene\"]\n",
    "        print(f\"Worinkg on gene {ko_gene}\")\n",
    "        try:\n",
    "            # Simulate knockout, it may not grow at all\n",
    "            model.reactions.get_by_id(reaction[\"id\"]).knock_out()\n",
    "            lmoma_result = lmoma(model, reference=dilution_result.fluxes)\n",
    "            df = pd.DataFrame(lmoma_result.fluxes)\n",
    "        except:\n",
    "            df = pd.DataFrame(dilution_result.fluxes)\n",
    "            df.fluxes = 0\n",
    "                   \n",
    "        df.index = df.index.rename(\"ID\")\n",
    "        df = df.reset_index()\n",
    "        df = df.assign(sample_id=reaction[\"gene\"])\n",
    "        \n",
    "        # rename some columns to be more compatible with other simulations\n",
    "        df = df.assign(author = \"Ec_core\")\n",
    "        df = df.assign(BiGG_ID = df.ID)\n",
    "        df = df.rename({\"fluxes\" : \"flux\"}, axis = 1)\n",
    "        \n",
    "        # calculate normalized fluxes \n",
    "        glucose_uptake = -1 * df[df['ID'] == 'EX_glc__D_e']['flux'].values[0]\n",
    "        df = df.assign(normalized_flux = lambda x: x.flux * 100 / glucose_uptake)\n",
    "        \n",
    "        df.to_csv(f\"../data/simulation_results/COBRA/core_model/delta_{ko_gene}.csv\")\n",
    "\n",
    "        all_data = pd.concat([all_data, df], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_all_data.to_csv(\"../data/simulation_results/COBRA/core_model/knockouts_all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make calculations for the EColiCore2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding exchange reaction EX_Biomass for boundary metabolite: Biomass\n",
      "Adding exchange reaction EX_4CRSOL_ex for boundary metabolite: 4CRSOL_ex\n",
      "Adding exchange reaction EX_5DRIB_ex for boundary metabolite: 5DRIB_ex\n",
      "Adding exchange reaction EX_ac_ex for boundary metabolite: ac_ex\n",
      "Adding exchange reaction EX_adp_c for boundary metabolite: adp_c\n",
      "Adding exchange reaction EX_AMOB_ex for boundary metabolite: AMOB_ex\n",
      "Adding exchange reaction EX_ca2_ex for boundary metabolite: ca2_ex\n",
      "Adding exchange reaction EX_cl_ex for boundary metabolite: cl_ex\n",
      "Adding exchange reaction EX_co2_ex for boundary metabolite: co2_ex\n",
      "Adding exchange reaction EX_coa_c for boundary metabolite: coa_c\n",
      "Adding exchange reaction EX_cobalt2_ex for boundary metabolite: cobalt2_ex\n",
      "Adding exchange reaction EX_cu2_ex for boundary metabolite: cu2_ex\n",
      "Adding exchange reaction EX_etoh_ex for boundary metabolite: etoh_ex\n",
      "Adding exchange reaction EX_fe2_ex for boundary metabolite: fe2_ex\n",
      "Adding exchange reaction EX_fe3_ex for boundary metabolite: fe3_ex\n",
      "Adding exchange reaction EX_foex for boundary metabolite: foex\n",
      "Adding exchange reaction EX_glc_DASH_D_ex for boundary metabolite: glc_DASH_D_ex\n",
      "Adding exchange reaction EX_glyc_ex for boundary metabolite: glyc_ex\n",
      "Adding exchange reaction EX_h_ex for boundary metabolite: h_ex\n",
      "Adding exchange reaction EX_h2_ex for boundary metabolite: h2_ex\n",
      "Adding exchange reaction EX_h2o_ex for boundary metabolite: h2o_ex\n",
      "Adding exchange reaction EX_k_ex for boundary metabolite: k_ex\n",
      "Adding exchange reaction EX_lac_ex for boundary metabolite: lac_ex\n",
      "Adding exchange reaction EX_meoh_ex for boundary metabolite: meoh_ex\n",
      "Adding exchange reaction EX_mg2_ex for boundary metabolite: mg2_ex\n",
      "Adding exchange reaction EX_mn2_ex for boundary metabolite: mn2_ex\n",
      "Adding exchange reaction EX_mobd_ex for boundary metabolite: mobd_ex\n",
      "Adding exchange reaction EX_mqn8_c for boundary metabolite: mqn8_c\n",
      "Adding exchange reaction EX_MTHTHF_ex for boundary metabolite: MTHTHF_ex\n",
      "Adding exchange reaction EX_nad_c for boundary metabolite: nad_c\n",
      "Adding exchange reaction EX_nadp_c for boundary metabolite: nadp_c\n",
      "Adding exchange reaction EX_nh4_ex for boundary metabolite: nh4_ex\n",
      "Adding exchange reaction EX_ni2_ex for boundary metabolite: ni2_ex\n",
      "Adding exchange reaction EX_o2_ex for boundary metabolite: o2_ex\n",
      "Adding exchange reaction EX_pi_c for boundary metabolite: pi_c\n",
      "Adding exchange reaction EX_pi_ex for boundary metabolite: pi_ex\n",
      "Adding exchange reaction EX_q8_c for boundary metabolite: q8_c\n",
      "Adding exchange reaction EX_so4_ex for boundary metabolite: so4_ex\n",
      "Adding exchange reaction EX_succ_ex for boundary metabolite: succ_ex\n",
      "Adding exchange reaction EX_zn2_ex for boundary metabolite: zn2_ex\n"
     ]
    }
   ],
   "source": [
    "model = cobra.io.read_sbml_model('../../../DataAnalysis/DataIntegrationProject/models/EColiCore2_compressed_bigg_names.sbml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize glucose consumption from medium - equiv to max exchange. \n",
    "model.objective = \"EX_glc_DASH_D_ex\"\n",
    "model.objective_direction = \"max\"\n",
    "\n",
    "# Simulate D 0.2 h-1\n",
    "model.reactions.Growth.bounds = (0.19,0.21)\n",
    "# Glucose uptake rate should more or less match Ishii, 2007\n",
    "# GUR for WT @ aerobic glucose = 2.87 mmol/h/gDW\n",
    "model.reactions.GLCptspp.bounds = (2.86,2.88)\n",
    "\n",
    "dilution_result = pfba(model)\n",
    "all_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write WT information\n",
    "df = pd.DataFrame(dilution_result.fluxes)\n",
    "df.index = df.index.rename(\"ID\")\n",
    "df = df.reset_index()\n",
    "df = df.assign(sample_id=\"WT\")\n",
    "        \n",
    "# rename some columns to be more compatible with other simulations\n",
    "df = df.assign(author = \"ECC2\")\n",
    "df = df.assign(BiGG_ID = df.ID)\n",
    "df = df.rename({\"fluxes\" : \"flux\"}, axis = 1)\n",
    "        \n",
    "# calculate normalized fluxes \n",
    "glucose_uptake = -1 * df[df['ID'] == 'EX_glc_DASH_D_ex']['flux'].values[0]\n",
    "df = df.assign(normalized_flux = lambda x: x.flux * 100 / glucose_uptake)\n",
    "\n",
    "df.to_csv('../data/simulation_results/COBRA/ECC2/WT_02.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([all_data, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on gene fbaA\n",
      "Working on gene fbaB\n",
      "Working on gene fbp\n",
      "Working on gene gnd\n",
      "Working on gene pfkA\n",
      "Working on gene pfkB\n",
      "Working on gene pgi\n",
      "Working on gene pgl\n",
      "Working on gene ppsA\n",
      "Working on gene pts\n",
      "Working on gene pykA\n",
      "Working on gene pykF\n",
      "Working on gene rpe\n",
      "Working on gene rpiA\n",
      "Working on gene rpiB\n",
      "Working on gene sdhCD\n",
      "Working on gene sucAB\n",
      "Working on gene talA\n",
      "Working on gene tktAB\n",
      "Working on gene tktB\n",
      "Working on gene tpi\n",
      "Working on gene zwf\n"
     ]
    }
   ],
   "source": [
    "for reaction in knockouts:\n",
    "    with model:        \n",
    "        ko_gene = reaction[\"gene\"]\n",
    "        print(f\"Working on gene {ko_gene}\")\n",
    "        try:\n",
    "            # Simulate knockout, it may not grow at all\n",
    "            model.reactions.get_by_id(reaction[\"id\"]).knock_out()\n",
    "            lmoma_result = lmoma(model, reference=dilution_result.fluxes)\n",
    "            df = pd.DataFrame(lmoma_result.fluxes)\n",
    "        except:\n",
    "            df = pd.DataFrame(dilution_result.fluxes)\n",
    "            df.fluxes = 0\n",
    "                   \n",
    "        df.index = df.index.rename(\"ID\")\n",
    "        df = df.reset_index()\n",
    "        df = df.assign(sample_id=reaction[\"gene\"])\n",
    "        \n",
    "        # rename some columns to be more compatible with other simulations\n",
    "        df = df.assign(author = \"ECC2\")\n",
    "        df = df.assign(BiGG_ID = df.ID)\n",
    "        df = df.rename({\"fluxes\" : \"flux\"}, axis = 1)\n",
    "        \n",
    "        # calculate normalized fluxes \n",
    "        glucose_uptake = -1 * df[df['ID'] == 'EX_glc_DASH_D_ex']['flux'].values[0]\n",
    "        df = df.assign(normalized_flux = lambda x: x.flux * 100 / glucose_uptake)\n",
    "        \n",
    "        df.to_csv(f\"../data/simulation_results/COBRA/ECC2/delta_{ko_gene}.csv\")\n",
    "\n",
    "        all_data = pd.concat([all_data, df], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv(\"../data/simulation_results/COBRA/ECC2/knockouts_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cameo-conda",
   "language": "python",
   "name": "cameo-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
