{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[0].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[0].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[0]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(null);\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.11.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.11.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.11.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.11.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.11.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.11.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.11.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.11.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.11.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.11.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.11.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.11.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.11.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.11.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.11.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.11.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.11.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.11.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.11.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.11.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import cobra\n",
    "from cameo import pfba\n",
    "from cameo.flux_analysis.simulation import lmoma\n",
    "\n",
    "import escher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define helper funcitons and IDs of knocked-out reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = Path(\"../data/models\")\n",
    "simulation_path = Path(\"../data/simulation_results\")\n",
    "data_path = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knockouts():\n",
    "    return [\n",
    "        {\"gene\": \"fbaA\", \"id\": \"FBA\"},\n",
    "        {\"gene\": \"fbaB\", \"id\": \"FBA\"},\n",
    "        {\"gene\": \"fbp\", \"id\": \"FBP\"},\n",
    "        {\"gene\": \"gnd\", \"id\": \"GND\"},\n",
    "        {\"gene\": \"pfkA\", \"id\": \"PFK\"},\n",
    "        {\"gene\": \"pfkB\", \"id\": \"PFK\"},\n",
    "        {\"gene\": \"pgi\", \"id\": \"PGI\"},\n",
    "        {\"gene\": \"pgl\", \"id\": \"PGL\"},\n",
    "        {\"gene\": \"ppsA\", \"id\": \"PPS\"},\n",
    "        {\"gene\": \"pts\", \"id\": \"GLCptspp\"},\n",
    "        {\"gene\": \"pykA\", \"id\": \"PYK\"},\n",
    "        {\"gene\": \"pykF\", \"id\": \"PYK\"},\n",
    "        {\"gene\": \"rpe\", \"id\": \"RPE\"},\n",
    "        {\"gene\": \"rpiA\", \"id\": \"RPI\"},\n",
    "        {\"gene\": \"rpiB\", \"id\": \"RPI\"},\n",
    "        {\"gene\": \"sdhCD\", \"id\": \"SUCDi\"},\n",
    "        {\"gene\": \"sucAB\", \"id\": \"AKGDH\"},\n",
    "        {\"gene\": \"talA\", \"id\": \"TALA\"},\n",
    "        {\"gene\": \"tktA\", \"id\": \"TKT1\"},\n",
    "        {\"gene\": \"tktB\", \"id\": \"TKT1\"},\n",
    "        {\"gene\": \"tpi\", \"id\": \"TPI\"},\n",
    "        {\"gene\": \"zwf\", \"id\": \"G6PDH2r\"},\n",
    "        {\"gene\": \"gpmA\", \"id\": \"PGM\"},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_escher(result):\n",
    "    escher.Builder(\n",
    "    map_name=\"iJO1366.Central metabolism\",\n",
    "    reaction_data=result.fluxes.to_dict(),\n",
    ").display_in_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataframe(\n",
    "    solution, sample=\"WT\", author=\"iML1515\", glucose_flux_id=\"EX_glc__D_e\"\n",
    "):\n",
    "    # Prepare basic DataFrame\n",
    "    df = pd.DataFrame(solution.fluxes)\n",
    "    df.index = df.index.rename(\"ID\")\n",
    "    df = df.reset_index()\n",
    "    df = df.assign(sample_id=sample)\n",
    "\n",
    "    # rename some columns to be more compatible with other simulations\n",
    "    df = df.assign(author=author)\n",
    "    df = df.assign(BiGG_ID=df.ID)\n",
    "    df = df.rename({\"fluxes\": \"flux\"}, axis=1)\n",
    "\n",
    "    # calculate normalized fluxes\n",
    "    glucose_uptake = -1 * df[df[\"ID\"] == glucose_flux_id][\"flux\"].values[0]\n",
    "    df = df.assign(normalized_flux=lambda x: x.flux * 100 / glucose_uptake)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_knockouts(\n",
    "    model,\n",
    "    ref_flux,\n",
    "    knockouts=get_knockouts(),\n",
    "    data_so_far=None,\n",
    "    save_path=None,\n",
    "    author=\"iML1515\",\n",
    "    glucose_flux_id=\"EX_glc__D_e\",\n",
    "):\n",
    "    # ref_flux is result.fluxes, save_path should be path to specific subfolder like COBRA/iML1515,\n",
    "    # prepare dataframe\n",
    "    if data_so_far is not None:\n",
    "        all_data = data_so_far\n",
    "    else:\n",
    "        all_data = pd.DataFrame()\n",
    "\n",
    "    # calculate knockouts\n",
    "    for reaction in knockouts:\n",
    "        with model:\n",
    "            ko_gene = reaction[\"gene\"]\n",
    "            print(f\"Working on gene {ko_gene}\")\n",
    "            try:\n",
    "                # Simulate knockout, it may not grow at all\n",
    "                model.reactions.get_by_id(reaction[\"id\"]).knock_out()\n",
    "                lmoma_result = lmoma(model, reference=ref_flux)\n",
    "                df = prepare_dataframe(\n",
    "                    lmoma_result,\n",
    "                    sample=ko_gene,\n",
    "                    author=author,\n",
    "                    glucose_flux_id=glucose_flux_id,\n",
    "                )\n",
    "                if save_path is not None:\n",
    "                    df.to_csv(save_path / f\"delta_{ko_gene}.csv\")\n",
    "                all_data = pd.concat([all_data, df], sort=False)\n",
    "            except:\n",
    "                print(f\"Unable to grow {ko_gene}!\")\n",
    "      \n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = pd.read_csv(data_path / \"datasets\" / \"long2019_tidy.csv\")\n",
    "long_df[\"sample_id\"] = long_df.Genotype\n",
    "long_df = long_df.assign(author=\"Long\").rename(\n",
    "            {\n",
    "                \"Measurement_ID\": \"BiGG_ID\",\n",
    "                \"Original_Value\": \"normalized_flux\",\n",
    "                \"Value\": \"flux\",\n",
    "                \"Original_ID\": \"ID\",\n",
    "            }, axis=1,)\n",
    "long_df = long_df[long_df[\"Measurement_Type\"] == \"flux\"]\n",
    "long_df = long_df[~long_df[\"BiGG_ID\"].isna()]\n",
    "# the same reaction as rpe\n",
    "long_df = long_df[long_df[\"sample_id\"] != \"sgcE\"]\n",
    "long_df = long_df[[\"BiGG_ID\", \"ID\", \"flux\", \"author\", \"sample_id\", \"normalized_flux\"]]\n",
    "exp_results = long_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_data = exp_results.query(\"sample_id == 'WT'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BiGG_ID</th>\n",
       "      <th>ID</th>\n",
       "      <th>flux</th>\n",
       "      <th>author</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>normalized_flux</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GLCptspp</td>\n",
       "      <td>Gluc.Ext + PEP -&gt; G6P + Pyr</td>\n",
       "      <td>8.58000</td>\n",
       "      <td>Long</td>\n",
       "      <td>WT</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PGI</td>\n",
       "      <td>G6P &lt;=&gt; F6P (net)</td>\n",
       "      <td>5.93736</td>\n",
       "      <td>Long</td>\n",
       "      <td>WT</td>\n",
       "      <td>69.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PFK</td>\n",
       "      <td>F6P + ATP -&gt; FBP</td>\n",
       "      <td>8.75160</td>\n",
       "      <td>Long</td>\n",
       "      <td>WT</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>FBP</td>\n",
       "      <td>FBP -&gt; F6P</td>\n",
       "      <td>1.81038</td>\n",
       "      <td>Long</td>\n",
       "      <td>WT</td>\n",
       "      <td>21.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>FBA</td>\n",
       "      <td>FBP &lt;=&gt; DHAP + GAP (net)</td>\n",
       "      <td>6.94122</td>\n",
       "      <td>Long</td>\n",
       "      <td>WT</td>\n",
       "      <td>80.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     BiGG_ID                           ID     flux author sample_id  \\\n",
       "21  GLCptspp  Gluc.Ext + PEP -> G6P + Pyr  8.58000   Long        WT   \n",
       "22       PGI            G6P <=> F6P (net)  5.93736   Long        WT   \n",
       "23       PFK             F6P + ATP -> FBP  8.75160   Long        WT   \n",
       "24       FBP                   FBP -> F6P  1.81038   Long        WT   \n",
       "25       FBA     FBP <=> DHAP + GAP (net)  6.94122   Long        WT   \n",
       "\n",
       "    normalized_flux  \n",
       "21            100.0  \n",
       "22             69.2  \n",
       "23            102.0  \n",
       "24             21.1  \n",
       "25             80.9  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate iML1515"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cobra.io.load_json_model(str(models_path / \"original_files\" / \"iML1515.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "iml1515 = model.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize glucose consumption from medium - equiv to max exchange. \n",
    "#model.objective = \"EX_glc__D_e\"\n",
    "#model.objective_direction = \"max\"\n",
    "# make glucose uptake to be through Pts\n",
    "model.reactions.GLCptspp.bounds = (0.0,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate and write WT information\n",
    "with model:\n",
    "    # Match glucose uptake rate (only for WT)\n",
    "    model.reactions.GLCptspp.bounds = (8.57,8.59)\n",
    "    batch_result = pfba(model)\n",
    "    df = prepare_dataframe(batch_result, author=\"iML1515\", sample=\"WT\", glucose_flux_id=\"EX_glc__D_e\")\n",
    "\n",
    "df.to_csv(simulation_path / \"COBRA\" / \"iML1515\" / \"batch_knockouts\" / \"WT.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on gene fbaA\n",
      "Working on gene fbaB\n",
      "Working on gene fbp\n",
      "Working on gene gnd\n",
      "Working on gene pfkA\n",
      "Working on gene pfkB\n",
      "Working on gene pgi\n",
      "Working on gene pgl\n",
      "Working on gene ppsA\n",
      "Working on gene pts\n",
      "Working on gene pykA\n",
      "Working on gene pykF\n",
      "Working on gene rpe\n",
      "Working on gene rpiA\n",
      "Working on gene rpiB\n",
      "Working on gene sdhCD\n",
      "Working on gene sucAB\n",
      "Working on gene talA\n",
      "Working on gene tktA\n",
      "Working on gene tktB\n",
      "Working on gene tpi\n",
      "Working on gene zwf\n",
      "Working on gene gpmA\n"
     ]
    }
   ],
   "source": [
    "res = simulate_knockouts(model = model, ref_flux=batch_result.fluxes, data_so_far=df, author=\"iML1515\", glucose_flux_id=\"EX_glc__D_e\")\n",
    "res.to_csv(simulation_path / \"COBRA\" / \"iML1515\" / \"batch_knockouts\" / \"knockouts_all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constrain iML1515 with experimental flux data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_fluxes = [\"RPI\", \"PGM\", \"PGK\", \"SUCOAS\", \"TKT1\",\n",
    "                   \"ASPTA\", \"ALATA_L\", \"VALTA\", \"ILETA\", \"PHETA1\", \"TYRTA\", \"TRPTA\",\n",
    "                   \"EX_atp_e\", \"EX_ac_e\", \"EX_co2_e\", \"EX_o2_e\", \"EX_nh4_e\", \"EX_so4_e\"]\n",
    "\n",
    "common_fluxes = set(batch_result.fluxes.index).intersection(set(exp_data.BiGG_ID.unique()))\n",
    "remove_ids = set([\"GLNS\", \"ASPTA\", \"EX_co2_e\", \"EX_nh4_e\", \"TKT2\", \"FUM\", \"GLUSy\", \"PSERT\", \"GHMT2r\", \"MTHFD\", \"EX_ac_e\", \"EX_o2_e\", \"MGSA\", \"ICDHyr\", \"GLYCL\"])\n",
    "\n",
    "common_fluxes = {f for f in common_fluxes if f not in remove_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACONTa',\n",
       " 'AKGDH',\n",
       " 'ALATA_L',\n",
       " 'ARGSL',\n",
       " 'ASNS2',\n",
       " 'CS',\n",
       " 'DAPDC',\n",
       " 'DAPE',\n",
       " 'EDA',\n",
       " 'EDD',\n",
       " 'EX_so4_e',\n",
       " 'FBA',\n",
       " 'FBP',\n",
       " 'G6PDH2r',\n",
       " 'GAPD',\n",
       " 'GLCptspp',\n",
       " 'GLU5K',\n",
       " 'GND',\n",
       " 'HISTD',\n",
       " 'ICL',\n",
       " 'ILETA',\n",
       " 'IPPS',\n",
       " 'LGTHL',\n",
       " 'MALS',\n",
       " 'MDH',\n",
       " 'ME1',\n",
       " 'ME2',\n",
       " 'METS',\n",
       " 'MTHFR2',\n",
       " 'NADTRHD',\n",
       " 'PDH',\n",
       " 'PFK',\n",
       " 'PGI',\n",
       " 'PGM',\n",
       " 'PHETA1',\n",
       " 'PPC',\n",
       " 'PPCK',\n",
       " 'PTAr',\n",
       " 'PYK',\n",
       " 'RPE',\n",
       " 'RPI',\n",
       " 'SERAT',\n",
       " 'SERD_L',\n",
       " 'SUCDi',\n",
       " 'SUCOAS',\n",
       " 'TALA',\n",
       " 'THRA',\n",
       " 'THRS',\n",
       " 'TKT1',\n",
       " 'TPI',\n",
       " 'TYRTA',\n",
       " 'VALTA'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PHETA1',\n",
       " 'VALTA',\n",
       " 'EX_so4_e',\n",
       " 'SUCOAS',\n",
       " 'PGM',\n",
       " 'ALATA_L',\n",
       " 'TYRTA',\n",
       " 'ILETA',\n",
       " 'TKT1',\n",
       " 'RPI']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f for f in common_fluxes if f in reversed_fluxes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EX_o2_e', 'EX_nh4_e', 'ASPTA', 'EX_co2_e', 'EX_ac_e']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f for f in remove_ids if f in reversed_fluxes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"TKT1\" in reversed_fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = exp_data.query(\"BiGG_ID in @common_fluxes\")\n",
    "exp_model = model.copy()\n",
    "\n",
    "for row in df.itertuples():\n",
    "        #print(f\"Adding constraint to flux {row.BiGG_ID}\")\n",
    "        #with exp_model:\n",
    "        r = exp_model.reactions.get_by_id(row.BiGG_ID)\n",
    "        flux = row.flux\n",
    "        if row.BiGG_ID in reversed_fluxes:\n",
    "            flux = -flux\n",
    "        r.bounds = (flux - 0.1, flux + 0.1)\n",
    "        #pfba(exp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_data.query(\"BiGG_ID in @remove_ids\").set_index(\"BiGG_ID\").join(exp_res.fluxes.loc[remove_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate WT\n",
    "exp_batch_result = pfba(exp_model)\n",
    "df = prepare_dataframe(exp_batch_result, sample=\"WT\", author=\"Exp_iML1515\", glucose_flux_id=\"EX_glc__D_e\" )\n",
    "df.to_csv(simulation_path / \"COBRA\" / \"Exp_iML1515\" / \"batch_knockouts\" / \"WT.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on gene fbaA\n",
      "Working on gene fbaB\n",
      "Working on gene fbp\n",
      "Working on gene gnd\n",
      "Working on gene pfkA\n",
      "Working on gene pfkB\n",
      "Working on gene pgi\n",
      "Working on gene pgl\n",
      "Working on gene ppsA\n",
      "Working on gene pts\n",
      "Working on gene pykA\n",
      "Working on gene pykF\n",
      "Working on gene rpe\n",
      "Working on gene rpiA\n",
      "Working on gene rpiB\n",
      "Working on gene sdhCD\n",
      "Working on gene sucAB\n",
      "Working on gene talA\n",
      "Working on gene tktA\n",
      "Working on gene tktB\n",
      "Working on gene tpi\n",
      "Working on gene zwf\n",
      "Working on gene gpmA\n"
     ]
    }
   ],
   "source": [
    "res = simulate_knockouts(model = model, ref_flux=exp_batch_result.fluxes, data_so_far=df, author=\"Exp_iML1515\", glucose_flux_id=\"EX_glc__D_e\")\n",
    "res.to_csv(simulation_path / \"COBRA\" / \"Exp_iML1515\" / \"batch_knockouts\" / \"knockouts_all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate EColiCore2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding exchange reaction EX_Biomass for boundary metabolite: Biomass\n",
      "Adding exchange reaction EX_4CRSOL_ex for boundary metabolite: 4CRSOL_ex\n",
      "Adding exchange reaction EX_5DRIB_ex for boundary metabolite: 5DRIB_ex\n",
      "Adding exchange reaction EX_ac_ex for boundary metabolite: ac_ex\n",
      "Adding exchange reaction EX_adp_c for boundary metabolite: adp_c\n",
      "Adding exchange reaction EX_AMOB_ex for boundary metabolite: AMOB_ex\n",
      "Adding exchange reaction EX_ca2_ex for boundary metabolite: ca2_ex\n",
      "Adding exchange reaction EX_cl_ex for boundary metabolite: cl_ex\n",
      "Adding exchange reaction EX_co2_ex for boundary metabolite: co2_ex\n",
      "Adding exchange reaction EX_coa_c for boundary metabolite: coa_c\n",
      "Adding exchange reaction EX_cobalt2_ex for boundary metabolite: cobalt2_ex\n",
      "Adding exchange reaction EX_cu2_ex for boundary metabolite: cu2_ex\n",
      "Adding exchange reaction EX_etoh_ex for boundary metabolite: etoh_ex\n",
      "Adding exchange reaction EX_fe2_ex for boundary metabolite: fe2_ex\n",
      "Adding exchange reaction EX_fe3_ex for boundary metabolite: fe3_ex\n",
      "Adding exchange reaction EX_foex for boundary metabolite: foex\n",
      "Adding exchange reaction EX_glc__D_ex for boundary metabolite: glc__D_ex\n",
      "Adding exchange reaction EX_glyc_ex for boundary metabolite: glyc_ex\n",
      "Adding exchange reaction EX_h_ex for boundary metabolite: h_ex\n",
      "Adding exchange reaction EX_h2_ex for boundary metabolite: h2_ex\n",
      "Adding exchange reaction EX_h2o_ex for boundary metabolite: h2o_ex\n",
      "Adding exchange reaction EX_k_ex for boundary metabolite: k_ex\n",
      "Adding exchange reaction EX_lac_ex for boundary metabolite: lac_ex\n",
      "Adding exchange reaction EX_meoh_ex for boundary metabolite: meoh_ex\n",
      "Adding exchange reaction EX_mg2_ex for boundary metabolite: mg2_ex\n",
      "Adding exchange reaction EX_mn2_ex for boundary metabolite: mn2_ex\n",
      "Adding exchange reaction EX_mobd_ex for boundary metabolite: mobd_ex\n",
      "Adding exchange reaction EX_mqn8_c for boundary metabolite: mqn8_c\n",
      "Adding exchange reaction EX_MTHTHF_ex for boundary metabolite: MTHTHF_ex\n",
      "Adding exchange reaction EX_nad_c for boundary metabolite: nad_c\n",
      "Adding exchange reaction EX_nadp_c for boundary metabolite: nadp_c\n",
      "Adding exchange reaction EX_nh4_ex for boundary metabolite: nh4_ex\n",
      "Adding exchange reaction EX_ni2_ex for boundary metabolite: ni2_ex\n",
      "Adding exchange reaction EX_o2_ex for boundary metabolite: o2_ex\n",
      "Adding exchange reaction EX_pi_c for boundary metabolite: pi_c\n",
      "Adding exchange reaction EX_pi_ex for boundary metabolite: pi_ex\n",
      "Adding exchange reaction EX_q8_c for boundary metabolite: q8_c\n",
      "Adding exchange reaction EX_so4_ex for boundary metabolite: so4_ex\n",
      "Adding exchange reaction EX_succ_ex for boundary metabolite: succ_ex\n",
      "Adding exchange reaction EX_zn2_ex for boundary metabolite: zn2_ex\n"
     ]
    }
   ],
   "source": [
    "model = cobra.io.read_sbml_model(str(models_path / \"original_files\" / \"EColiCore2_compressed_bigg_names.sbml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecc = model.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate medium as in iML1515\n",
    "med_ids = [reaction + 'x' for reaction in iml1515.medium]\n",
    "\n",
    "for reaction in model.medium:\n",
    "    if reaction not in med_ids:\n",
    "        model.reactions.get_by_any(reaction)[0].bounds = (0,1000)\n",
    "    else:\n",
    "        model.reactions.get_by_any(reaction)[0].bounds = (-1000,1000)\n",
    "\n",
    "# set glucose level to match iML1515\n",
    "model.exchanges.EX_glc__D_ex.bounds = (-10.0,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate and write WT information\n",
    "with model:\n",
    "    # Match glucose uptake rate (only for WT)\n",
    "    model.reactions.GLCptspp.bounds = (8.5,8.59)\n",
    "    batch_result = pfba(model)\n",
    "    df = prepare_dataframe(batch_result, author=\"ECC2\", glucose_flux_id=\"EX_glc__D_ex\")\n",
    "    df.to_csv(simulation_path / \"COBRA\" / \"ECC2\" / \"batch_knockouts\" / \"WT.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on gene fbaA\n",
      "Working on gene fbaB\n",
      "Working on gene fbp\n",
      "Working on gene gnd\n",
      "Working on gene pfkA\n",
      "Working on gene pfkB\n",
      "Working on gene pgi\n",
      "Working on gene pgl\n",
      "Working on gene ppsA\n",
      "Working on gene pts\n",
      "Working on gene pykA\n",
      "Working on gene pykF\n",
      "Working on gene rpe\n",
      "Working on gene rpiA\n",
      "Working on gene rpiB\n",
      "Working on gene sdhCD\n",
      "Working on gene sucAB\n",
      "Working on gene talA\n",
      "Working on gene tktA\n",
      "Working on gene tktB\n",
      "Working on gene tpi\n",
      "Working on gene zwf\n",
      "Working on gene gpmA\n"
     ]
    }
   ],
   "source": [
    "res = simulate_knockouts(model = model, ref_flux=batch_result.fluxes, data_so_far=df, author=\"ECC2\", glucose_flux_id=\"EX_glc__D_ex\")\n",
    "res.to_csv(simulation_path / \"COBRA\" / \"ECC2\" / \"batch_knockouts\" /  \"knockouts_all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constrain ECC2 by experimentally measured fluxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify which fluxes could be constrainted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_fluxes = [\"RPI\", \"TKT1\",\n",
    "                   \"ASPTA\", \"ALATA_L\", \"VALTA\", \"ILETA\", \"PHETA1\", \"TYRTA\", \"TRPTA\",\n",
    "                   \"EX_atp_e\", \"EX_ac_e\", \"EX_co2_e\", \"EX_o2_e\", \"EX_nh4_e\", \"EX_so4_e\"]\n",
    "\n",
    "common_fluxes = set(batch_result.fluxes.index).intersection(set(exp_data.BiGG_ID.unique()))\n",
    "remove_ids = set([\"GLNS\", \"ASPTA\", \"EX_co2_e\", \"EX_nh4_e\", \"TKT2\", \"FUM\", \"GLUSy\", \"PSERT\", \"GHMT2r\", \"MTHFD\", \"EX_ac_e\", \"EX_o2_e\", \"MGSA\", \"GLYCL\", \"PPC\", \"PTAr\"])\n",
    "\n",
    "common_fluxes = {f for f in common_fluxes if f not in remove_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACONTa',\n",
       " 'AKGDH',\n",
       " 'CS',\n",
       " 'EDA',\n",
       " 'EDD',\n",
       " 'FBA',\n",
       " 'FBP',\n",
       " 'G6PDH2r',\n",
       " 'GAPD',\n",
       " 'GLCptspp',\n",
       " 'GND',\n",
       " 'ICDHyr',\n",
       " 'ICL',\n",
       " 'MALS',\n",
       " 'MDH',\n",
       " 'ME1',\n",
       " 'ME2',\n",
       " 'NADTRHD',\n",
       " 'PDH',\n",
       " 'PFK',\n",
       " 'PGI',\n",
       " 'PGM',\n",
       " 'PPCK',\n",
       " 'PYK',\n",
       " 'RPE',\n",
       " 'RPI',\n",
       " 'SUCDi',\n",
       " 'SUCOAS',\n",
       " 'TALA',\n",
       " 'TKT1',\n",
       " 'TPI'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = exp_data.query(\"BiGG_ID in @common_fluxes\")\n",
    "exp_model = model.copy()\n",
    "\n",
    "for row in df.itertuples():\n",
    "        #print(f\"Setting bounds for reaction {row.BiGG_ID}\")\n",
    "        r = exp_model.reactions.get_by_id(row.BiGG_ID)\n",
    "        flux = row.flux\n",
    "        if row.BiGG_ID in reversed_fluxes:\n",
    "            flux = -flux\n",
    "        r.bounds = (flux - 0.1, flux + 0.1)\n",
    "        #pfba(exp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp_data.query(\"BiGG_ID in @remove_ids\").set_index(\"BiGG_ID\").join(exp_batch_result.fluxes.loc[remove_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate WT\n",
    "exp_batch_result = pfba(exp_model)\n",
    "df = prepare_dataframe(exp_batch_result, sample=\"WT\", author=\"Exp_ECC2\", glucose_flux_id=\"EX_glc__D_ex\" )\n",
    "df.to_csv(simulation_path / \"COBRA\" / \"Exp_ECC2\" / \"batch_knockouts\" / \"WT.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on gene fbaA\n",
      "Working on gene fbaB\n",
      "Working on gene fbp\n",
      "Working on gene gnd\n",
      "Working on gene pfkA\n",
      "Working on gene pfkB\n",
      "Working on gene pgi\n",
      "Working on gene pgl\n",
      "Working on gene ppsA\n",
      "Working on gene pts\n",
      "Working on gene pykA\n",
      "Working on gene pykF\n",
      "Working on gene rpe\n",
      "Working on gene rpiA\n",
      "Working on gene rpiB\n",
      "Working on gene sdhCD\n",
      "Working on gene sucAB\n",
      "Working on gene talA\n",
      "Working on gene tktA\n",
      "Working on gene tktB\n",
      "Working on gene tpi\n",
      "Working on gene zwf\n",
      "Working on gene gpmA\n"
     ]
    }
   ],
   "source": [
    "res = simulate_knockouts(model = model, ref_flux=exp_batch_result.fluxes, data_so_far=df, author=\"Exp_ECC2\", glucose_flux_id=\"EX_glc__D_ex\")\n",
    "res.to_csv(simulation_path / \"COBRA\" / \"Exp_ECC2\" / \"batch_knockouts\" / \"knockouts_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cameo-conda",
   "language": "python",
   "name": "cameo-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
